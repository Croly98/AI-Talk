<!DOCTYPE html>
<!--
=== AI TALK PIPELINE EXPLANATION ===
This is a voice-to-AI conversation app that:
1. Enter in the API keys for GPT and Azure Speech Services
1. Listens to your voice (Speech-to-Text using Azure)
2. Sends what you said to OpenAI GPT-3.5-turbo for a response
3. Speaks the AI's response back to you (Text-to-Speech using Azure)
-->
<html lang="en">
<head>
    <title>AI Talk Pipeline gpt-3.5-turbo</title>
    <meta charset="utf-8" />
    <style>
        /* === VISUAL STYLING === */
        
        body {
            font-family: 'Segoe UI', -apple-system, BlinkMacSystemFont, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            text-align: center;
            max-width: 600px;
            width: 90%;
        }

        h1 {
            color: #333;
            margin-bottom: 30px;
            font-weight: 300;
            font-size: 2.5em;
        }

        .config-section {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
        }

        .config-row {
            display: flex;
            margin-bottom: 15px;
            align-items: center;
        }

        .config-row label {
            width: 150px;
            text-align: right;
            margin-right: 15px;
            font-weight: 500;
        }

        .config-row input {
            flex: 1;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            font-size: 14px;
        }

        #talkButton {
            background: linear-gradient(45deg, #28a745, #20c997);
            color: white;
            border: none;
            border-radius: 50px;
            padding: 20px 40px;
            font-size: 18px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 10px 20px rgba(40, 167, 69, 0.3);
        }

        #talkButton:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 15px 30px rgba(40, 167, 69, 0.4);
        }

        #talkButton:disabled {
            background: #6c757d;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        .status {
            margin: 20px 0;
            font-size: 16px;
            font-weight: 500;
            min-height: 24px;
        }

        .status.listening { color: #dc3545; }
        .status.processing { color: #fd7e14; }
        .status.speaking { color: #28a745; }
        .status.ready { color: #6c757d; }

        .conversation {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            margin-top: 20px;
            text-align: left;
            max-height: 400px;
            overflow-y: auto;
        }

        .message {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 8px;
        }

        .user-message {
            background: #e3f2fd;
            margin-left: 20px;
        }

        .ai-message {
            background: #f3e5f5;
            margin-right: 20px;
        }

        .pulse {
            animation: pulse 1.5s ease-in-out infinite;
        }

        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
    </style>
</head>
<body>
    <!--Main text + User key input--> 
    <div class="container">
        <h1>AI Talk Pipeline GPT-3.5-turbo</h1>

        <div class="config-section">
            <div class="config-row">
                <label>Azure Speech Key:</label>
                <input type="text" id="speechKey" placeholder="Your Azure Speech Services key">
            </div>
            <div class="config-row">
                <label>Azure Region:</label>
                <input type="text" id="speechRegion" placeholder="e.g. swedencentral">
            </div>
            <div class="config-row">
                <label>OpenAI API Key:</label>
                <input type="text" id="openaiKey" placeholder="Your OpenAI API key">
            </div>
        </div>

        <button id="talkButton">ðŸŽ¤ Talk to AI</button>

        <div id="status" class="status ready">Ready - Click to start talking</div>

        <div id="conversation" class="conversation" style="display: none;">
            <div id="conversationHistory"></div>
        </div>
    </div>

    <!-- Load Microsoft's Speech SDK - this gives us speech-to-text and text-to-speech capabilities -->
    <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
    <script>
        /* === MAIN APPLICATION CLASS ===
           This class handles the entire voice conversation pipeline, it managesL
           State (whether the system is busy or free
           UI elements (button, status, conversation history
           The actual pipeline flow
        */

        class AIPipeline {
            constructor() {
                // Prevent multiple conversations from running at once
                this.isProcessing = false;
                // Store conversation for context (so AI remembers what we talked about)
                this.conversationHistory = [];
                // Get references to HTML elements
                this.initializeElements();
                // Set up button clicks and speech SDK
                this.bindEvents();
            }

            /* Get references to all the HTML elements we need to control */
            initializeElements() {
                this.talkButton = document.getElementById('talkButton');           // The "Talk to AI" button
                this.statusDiv = document.getElementById('status');               // Shows current status (listening, thinking, etc.)
                this.conversationDiv = document.getElementById('conversation');   // Container for conversation history
                this.historyDiv = document.getElementById('conversationHistory'); // The actual conversation messages
                this.speechKeyInput = document.getElementById('speechKey');       // Azure Speech API key input
                this.speechRegionInput = document.getElementById('speechRegion'); // Azure region input
                this.openaiKeyInput = document.getElementById('openaiKey');       // OpenAI API key input
            }

            bindEvents() {
                this.talkButton.addEventListener('click', () => this.startConversation());

                if (!!window.SpeechSDK) {
                    this.SpeechSDK = window.SpeechSDK;
                    this.updateStatus('Ready - Click to start talking', 'ready');
                } else {
                    this.updateStatus('Speech SDK not loaded', 'error');
                }
            }

            updateStatus(message, type) {
                this.statusDiv.textContent = message;
                this.statusDiv.className = `status ${type}`;

                if (type === 'processing') {
                    this.statusDiv.classList.add('pulse');
                } else {
                    this.statusDiv.classList.remove('pulse');
                }
            }

            /* === THE MAIN CONVERSATION PIPELINE ===
               This is where the magic happens! Three steps:
               1. Listen to your voice - convert to text
               2. Send text to OpenAI - get AI response
               3. Convert AI response to speech â†’ speak it out loud */
            async startConversation() {
                // Don't start if we're already processing
                if (this.isProcessing) return;

                // Make sure user entered their API keys
                if (!this.validateConfig()) {
                    alert('Please fill in all configuration fields');
                    return;
                }

                // Lock the button so user can't click multiple times
                this.isProcessing = true;
                this.talkButton.disabled = true;

                try {
                    // === STEP 1: SPEECH TO TEXT ===
                    // Turn on microphone and listen for user's voice
                    this.updateStatus('Listening...', 'listening');
                    const userText = await this.speechToText();

                    if (userText) {
                        // Show what user said in the conversation
                        this.addToConversation('user', userText);

                        // === STEP 2: SEND TO OPENAI ===
                        // Send user's text to GPT-3.5-turbo for a response
                        this.updateStatus('AI is thinking...', 'processing');
                        const aiResponse = await this.callOpenAI(userText);

                        if (aiResponse) {
                            // Show AI's response in the conversation
                            this.addToConversation('ai', aiResponse);

                            // === STEP 3: TEXT TO SPEECH ===
                            // Convert AI's text response back to spoken audio
                            this.updateStatus('Speaking...', 'speaking');
                            await this.textToSpeech(aiResponse);
                        }
                    }
                } catch (error) {
                    console.error('Pipeline error:', error);
                    this.updateStatus('Error occurred: ' + error.message, 'error');
                } finally {
                    this.isProcessing = false;
                    this.talkButton.disabled = false;
                    this.updateStatus('Ready - Click to start talking', 'ready');
                }
            }

            validateConfig() {
                return this.speechKeyInput.value.trim() &&
                       this.speechRegionInput.value.trim() &&
                       this.openaiKeyInput.value.trim();
            }

            /* === SPEECH TO TEXT FUNCTION ===
               Uses Azure Speech SDK to listen to microphone and convert speech to text */
            speechToText() {
                return new Promise((resolve, reject) => {
                    // Set up Azure Speech service with user's API key and region
                    const speechConfig = this.SpeechSDK.SpeechConfig.fromSubscription(
                        this.speechKeyInput.value.trim(),
                        this.speechRegionInput.value.trim()
                    );
                    // Set language to English (US)
                    speechConfig.speechRecognitionLanguage = "en-US";

                    // Configure to use the default microphone
                    const audioConfig = this.SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();
                    // Create the speech recognizer
                    const recognizer = new this.SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);

                    recognizer.recognizeOnceAsync(
                        (result) => {
                            recognizer.close();
                            if (result.reason === this.SpeechSDK.ResultReason.RecognizedSpeech) {
                                resolve(result.text);
                            } else {
                                reject(new Error('Speech recognition failed'));
                            }
                        },
                        (error) => {
                            recognizer.close();
                            reject(new Error('Speech recognition error: ' + error));
                        }
                    );
                });
            }

            /* === OPENAI API CALL ===
               Sends user's text to OpenAI GPT-3.5-turbo and gets AI response */
            async callOpenAI(userMessage) {
                try {
                    // Make HTTP request to OpenAI's chat completion API
                    const response = await fetch('https://api.openai.com/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': `Bearer ${this.openaiKeyInput.value.trim()}`  // User's OpenAI API key
                        },
                        body: JSON.stringify({
                            model: 'gpt-3.5-turbo',  // Using GPT-3.5-turbo model (fast and affordable)
                            messages: [
                                {
                                    role: 'system',  // System prompt - tells AI how to behave
                                    content: 'You are a helpful AI assistant. Keep your responses conversational and concise, suitable for speech synthesis. You have access to real-time information and can browse the internet.'
                                },
                                ...this.conversationHistory.slice(-10), // Include last 10 messages for context
                                {
                                    role: 'user',   // The current user message
                                    content: userMessage
                                }
                            ],
                           max_tokens: 150,    // Limit response length (good for QUICK speech)
                            temperature: 0.7    // How creative/random the responses are (0.7 is balanced)
                        })
                    });

                    if (!response.ok) {
                        throw new Error(`OpenAI API error: ${response.status}`);
                    }

                    const data = await response.json();
                    return data.choices[0].message.content;
                } catch (error) {
                    throw new Error('OpenAI request failed: ' + error.message);
                }
            }

            /* === TEXT TO SPEECH FUNCTION ===
               Uses Azure Speech SDK to convert AI's text response into spoken audio */
            textToSpeech(text) {
                return new Promise((resolve, reject) => {
                    // Set up Azure Speech service (same config as speech-to-text)
                    const speechConfig = this.SpeechSDK.SpeechConfig.fromSubscription(
                        this.speechKeyInput.value.trim(),
                        this.speechRegionInput.value.trim()
                    );

                    // Create speech synthesizer (converts text to audio)
                    const synthesizer = new this.SpeechSDK.SpeechSynthesizer(speechConfig);

                    synthesizer.speakTextAsync(
                        text,
                        (result) => {
                            synthesizer.close();
                            if (result.reason === this.SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
                                resolve();
                            } else {
                                reject(new Error('Speech synthesis failed'));
                            }
                        },
                        (error) => {
                            synthesizer.close();
                            reject(new Error('Speech synthesis error: ' + error));
                        }
                    );
                });
            }

            /* === ADD MESSAGE TO CONVERSATION ===
               Stores messages for AI context AND displays them on screen */
            addToConversation(role, message) {
                // Store in conversation history for OpenAI (so AI remembers context)
                const apiRole = role === 'ai' ? 'assistant' : 'user';  // OpenAI uses 'assistant' instead of 'ai'
                this.conversationHistory.push({ role: apiRole, content: message });

                // Create visual message bubble on screen
                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${role}-message`;  // CSS styling for user vs AI messages
                messageDiv.innerHTML = `<strong>${role === 'user' ? 'You' : 'AI'}:</strong> ${message}`;

                // Add to conversation display
                this.historyDiv.appendChild(messageDiv);
                this.conversationDiv.style.display = 'block';  // Show conversation area
                this.conversationDiv.scrollTop = this.conversationDiv.scrollHeight;  // Scroll to bottom
            }
        }

        // Initialize the pipeline when page loads
        document.addEventListener('DOMContentLoaded', () => {
            new AIPipeline();
        });
    </script>
</body>
</html>